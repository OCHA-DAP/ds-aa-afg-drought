---
title: "Download Snow Melt Date"
editor: visual
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    self-contained: true
    embed-resoures: true
    smooth-scroll: true
execute:
  include: true
  echo: true
  warning: false
  message: false
  eval: true
  results: "asis"
  out.width: "100%"
---

- This qmd is not written to be knit/rendered. Quarto is just used as it is nice format for writing annotations/notes.
- This is the `{rgee}` earth engine code to run and download zonal statistics for first snow melt date.
- The output files are saved as blob storage on dev storage account in the `projects` container here:
    +`ds-aa-afg-drought/processed/vector/modis_first_day_no_snow_m_y2006_14e_120c.csv`
    +`ds-aa-afg-drought/processed/vector/modis_first_day_no_snow_m_composite_14e_120c.csv`

This code has been copied into the quarto book for illustration of methods. However, in the quarto book the earth engine code is not evaluated at run time as those chunks are defined with `#| eval: false`. This is done for several reasons:
  - We don't want to run the GEE code every time we render the book.
  - GEE visualizations don't persist on a website for more than 4 hours, so we use a screenshot work-around as shown in book

- Nonetheless for full transparency of where and how code was run, the download code is illustrated here. I've added a `boolean` `write_to_blob` parameter which is set to `FALSE` at top of script so the reviewer can feel free to run code without worry of overwriting anything.
- Additionally, it's nice to be able to run the code interactively here and leverage the nice visualizations built into `GEE`/`{rgee}` that can't be easily displayed in a book.


- Method adopted from [Armstrong et al., 2023](https://developers.google.com/earth-engine/tutorials/community/identifying-first-day-no-snow)


```{r}

library(sf)
library(tidyverse)
library(gghdx)
library(glue)
library(ggiraph)
library(glue)
library(rgee)
library(tidyrgee) # recommend github verison : devtools::install_github("r-tidy-remote-sensing/tidyrgee")

# ee_check()
ee_Initialize()
write_to_blob <- c(TRUE,FALSE)[2]
```


## Load GEE layers

```{r}
basin_levels = c("4"=4,"5"=5,"6"=6,"7"= 7)

adm1_fc <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level1")
adm0_fc <- ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level0")

# filter adm1 to get only those in Afghanistan
adm1_afghanistan <- adm1_fc$filter(ee$Filter$eq("ADM0_NAME", "Afghanistan"))
adm0_afghanistan <- adm0_fc$filter(ee$Filter$eq("ADM0_NAME", "Afghanistan"))
fc_faryab <- adm1_afghanistan$filter(ee$Filter$eq("ADM1_NAME","Faryab"))

# hydro basins
l_hybas = map(basin_levels,\(x)ee$FeatureCollection(paste0('WWF/HydroSHEDS/v1/Basins/hybas_',x)))
# hydro sheds rivers
fc_river = ee$FeatureCollection('WWF/HydroSHEDS/v1/FreeFlowingRivers')
```

## Hydro vis

Just for fun, could come in handy later
```{r}


img_river = ee$Image()$byte()$paint(fc_river, 'RIV_ORD', 2); # easier format to visualize
riv_vis = list(
  min= 1,
  max= 10,
  palette= list('#08519c', '#3182bd', '#6baed6', '#bdd7e7', '#eff3ff')
)
hybas_vis = list(
  color= '#808080',
  strokeWidth= 1
)


Map$centerObject(fc_faryab,7) # zoom set for all maps in doc
m_hydro <- Map$addLayer(img_river,riv_vis, "hydroshed rivers")+
  Map$addLayer(l_hybas$`5`$style(fillColor="#00000000", color = "darkblue", width =1))+
  Map$addLayer(fc_faryab$style(fillColor = "#00000000", color = "red"))+
  Map$addLayer(adm0_afghanistan$style(fillColor="#00000000", color = "black", width = 5))

m_hydro

```

## Analysis masks
What i am doing is more annotated in book. But basically trying out 2 methods to create the analysis area mask

method 1: base mask on a "typical snow year" - see book for how i defined that as 2006
method 2: base mask on a more complex compositing method

This chunk create mask with method 1
```{r}
# Define complete collection
complete_col <- ee$ImageCollection("MODIS/061/MOD10A1")$
  select("NDSI_Snow_Cover")
# Define water mask
water_mask <- ee$Image("MODIS/MOD44W/MOD44W_005_2000_02_24")$
  select("water_mask")$Not()

# Define snow cover ephemeral mask
snow_cover_ephem <- complete_col$
  filterDate("2006-01-01", "2007-01-01")$
  map(function(img) img$gte(10))$
  sum()$
  gte(14) # at least 2 weeks > 10 %

# Define snow cover constraint mask
snow_cover_const <- complete_col$
  filterDate("2006-01-01", "2007-01-01")$
  map(function(img) img$gte(10))$
  sum()$
  lte(120) # if LTE 200 days 1, otherwise 0

analysis_mask_2006 <- water_mask$
  multiply(snow_cover_ephem)$
  multiply(snow_cover_const)
```

chunk here implements method 2.

Step 1 - create function to implement the function for any year provided
```{r}

create_snow_masks <- function(year) {

  water_mask <- ee$Image("MODIS/MOD44W/MOD44W_005_2000_02_24")$
  select("water_mask")$Not()

  start <- ee$Date$fromYMD(year, 1, 1)
  end <- ee$Date$fromYMD(year, 12, 31)

   modis_snow <- ee$ImageCollection("MODIS/061/MOD10A1")$
     select("NDSI_Snow_Cover")

  # Filter MODIS snow cover dataset for the given year
  snow_lte_120d <- modis_snow$
    filterDate(start, end)$
    map(function(img) img$gte(10))$
    sum()$
    lte(120)

  snow_gte_14d <- modis_snow$
    filterDate(start, end)$
    map(function(img) img$gte(10))$
    sum()$
    gte(14)

  water_mask$multiply(snow_gte_14d)$
    multiply(snow_lte_120d)
}
```

Step 2 - define year range of interest and iterate the function throught the list
```{r}
start_year <- 2000
end_year <-  2024
years <- ee$List$sequence(start_year, end_year)

yearly_analysis_masks <- years$map(ee_utils_pyfunc(function(year) {
  create_snow_masks(year)
  }
 )
)
```


Step 3 - Composite the yearly masks by creating a mask of 70% aggreement across all years
```{r}
num_years <- length(start_year:end_year)

# Aggregate across years to calculate the percentage of agreement

composite_analysis_mask <- ee$ImageCollection$fromImages(yearly_analysis_masks)$
  sum()$
  divide(num_years)$
  gte(0.7) # Agreement threshold: >70% of years

```


```{r}

vis_params_composite <- list(min = 0, max = 1, palette = c("white", "darkgreen"))

m_mask_comparison <-
   Map$addLayer(analysis_mask_2006$mask(analysis_mask_2006), list(palette= "black"),"Analysis Mask 2006")+
  Map$addLayer(composite_analysis_mask$mask(composite_analysis_mask), vis_params_composite, "Composite Ephemeral")+
  Map$addLayer(fc_faryab$style(fillColor = "#00000000", color = "red"))

m_mask_comparison
```


## Calculate Date Snow Disappearance

Below we calculate the first day-of-year (DOY) of now snow at the pixel level using both the 2006 single year mask and the composite mask

```{r}

# Define function to add date bands
add_date_bands <- function(img) {
  # Get image date
  date <- img$date()

  # Get calendar day-of-year
  cal_doy <- date$getRelative('day', 'year')

  # Get relative day-of-year
  # rel_doy <- date$difference(ee$Date(start_date), 'day')

  # Get the date as milliseconds from Unix epoch
  millis <- date$millis()

  # Add date bands to the image
  date_bands <- ee$Image$constant(
    c(
      cal_doy,
      # rel_doy,
      millis,
      start_year
      ))$
    rename(
      c("calDoy",
        # "relDoy",
        "millis", "year"))$
    cast(list(calDoy = "int",
              # relDoy = "int",
              millis = "long", year = "int"))

  img$addBands(date_bands)$set(list(millis = millis))
}

```



```{r}

annual_snow_disappearance <- function(start_year,end_year, mask_selection){
  years <- ee$List$sequence(start_year,end_year)
  annual_list <- years$map(ee_utils_pyfunc(function(year) {
    # Define date range for the year
    start_date <- ee$Date$fromYMD(year, 1, 1)$advance(1 - 1, "day") # 1 - 1 because first 1 used to be start_doy - can be used when we don't want to start Jan 1.
    end_date <- start_date$advance(250, "day")$advance(1, "day") # set to 250 so we can run for 2024 as well (snow is always melted by 250)

    sys_date <- ee$Date$fromYMD(year, 1, 1)
    # Filter collection by year
    year_col <- complete_col$filterDate(start_date, end_date)

    # Generate no-snow image
    no_snow_img <- year_col$
      map(add_date_bands)$
      sort("millis")$
      reduce(ee$Reducer$min(
        4 # get min across 4 bands
      ))$
      rename(c("snowCover",
               "calDoy",
               "millis", "year"))$
      updateMask(mask_selection)$
      set("year", year)$
      set("system:time_start",sys_date)

    no_snow_img$updateMask(no_snow_img$select("snowCover")$eq(0))
  }))
  ee$ImageCollection$fromImages(annual_list)
}

```

implement function
```{r}
annual_col_composite <- annual_snow_disappearance(start_year=2000,end_year = 2024, mask_selection = composite_analysis_mask)
annual_col_2006 <- annual_snow_disappearance(start_year=2000,end_year = 2024, mask_selection = analysis_mask_2006)
```


### Snow Melt Map

- For the purpose of map visualization we just map the DOY of snow disappearance using the method 1 mask (single year)
- Below you see the our analysis mask, AOI, and a raster colored by approximate date of **snow disappearance in 2023** where yellow colors represent later snow melt dates (higher altitudes) and darker blue colors are earlier snow melt dates


This slider widget is pretty cool and you can't see it in the book!
```{r}


# Define visualization arguments
viz_doy <- list(
  bands = c("calDoy"),
  min = 50,
  max = 150,
  palette = c("#0D0887", "#5B02A3", "#9A179B", "#CB4678", "#EB7852", "#FBB32F", "#F0F921")
)

# Visualize a specific year

first_day_no_snow_2023 <- annual_col_2006$filter(ee$Filter$eq("year", 2023))$first()
first_day_no_snow_2024 <- annual_col_2006$filter(ee$Filter$eq("year", 2024))$first()

m_no_snow_2023 <- Map$addLayer(first_day_no_snow_2023, viz_doy, "First day of no snow, 2023")+
  Map$addLayer(fc_faryab$style(fillColor = "#00000000", color = "red"))



m_no_snow_2024 <- Map$addLayer(first_day_no_snow_2024, viz_doy, "First day of no snow, 2024")+
  Map$addLayer(fc_faryab$style(fillColor = "#00000000", color = "red"))

m_no_snow_2023 | m_no_snow_2024
## Zonal Stats
```

- run the zonal stats (mean) per admin of interest for the images produced with each method.
- You can run - how long it takes kind of depends on external factors. I've had it run in a few minutes up to 40 minutes

```{r}

fc_filtered <- adm1_afghanistan$filter(
  ee$Filter$inList("ADM1_NAME", aoi_adm1)
  )

ldf <- list(
  "m_y2006" = annual_col_2006,
  "m_composite" = annual_col_composite
) |>
  imap(
    \(ict,nmt){
      cat(nmt,"\n")
      tic_annual <-  as_tidyee(ict$select('calDoy')) # this is really the only band we care about
      df_snowmelt <- ee_extract_tidy(
        x = tic_annual,
        y=fc_filtered,
        stat = "mean",
        scale = 500
      )
      if(write_to_blob){
        cumulus::blob_write(
          df_snowmelt,
          stage = "dev" ,
          name = glue("ds-aa-afg-drought/processed/vector/modis_first_day_no_snow_{nmt}_14e_120c.csv"),
          container = "projects"
        )

      }
      return(df_snow_melt)
    }
  )


```
